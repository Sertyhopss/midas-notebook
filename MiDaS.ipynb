{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "alpha-bathroom",
      "metadata": {
        "id": "alpha-bathroom"
      },
      "source": [
        "# MiDaS\n",
        "\n",
        "### Описание\n",
        "\n",
        "[MiDaS](https://arxiv.org/abs/1907.01341) позволяет вычислять карту глубины по изображению. Этот блокнот даёт возможность запускать несколько различных моделей (например, `v2.1` / `v3 Hybrid` / `v3 Large`) на вашем наборе изображений. \n",
        "\n",
        "Перед использованием создайте на своём гугл-диске папку `midas-source`, в которую поместите изображения, карты глубин которых вы хотите получить. Не используйте в наименовании файлов пробелы. После обработки результаты будут помещены в папку `midas-result` на вашем хранилище.\n",
        "\n",
        "Этот блокнот рассчитан на работу в Google Colab, чтобы использовать вычислительные мощности облака, а не вашего компьютера. Если вы всё ещё не там, необходимо сделать следующее:\n",
        "\n",
        "1. Перейти по ссылке https://colab.research.google.com/\n",
        "2. Выбрать пункт \"GitHub\"\n",
        "3. Вставить туда ссылку на этот блокнот (на текущий момент это https://github.com/Sertyhopss/midas-notebook/blob/master/MiDaS.ipynb)\n",
        "4. Выбрать файл MiDaS.ipynb\n",
        "\n",
        "или, если файл хранится у вас локально:\n",
        "\n",
        "1. Перейти по ссылке https://colab.research.google.com/\n",
        "2. Выбрать пункт \"Загрузить\"\n",
        "3. Вставить в открывшееся окно текущий файл\n",
        "\n",
        "Приятного использования!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Установка необходимых зависимостей"
      ],
      "metadata": {
        "id": "wrPLi36ib3Bl"
      },
      "id": "wrPLi36ib3Bl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "parental-toyota",
      "metadata": {
        "attributes": {
          "classes": [
            "shell"
          ],
          "id": ""
        },
        "id": "parental-toyota"
      },
      "outputs": [],
      "source": [
        "pip install timm opencv-python torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "scientific-burning",
      "metadata": {
        "id": "scientific-burning"
      },
      "source": [
        "### Импорт зависимостей и получение разрешения на использование google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "graphic-swing",
      "metadata": {
        "id": "graphic-swing"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import urllib.request\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "DRIVE = Path('/content/drive/MyDrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Определение источника изображений\n",
        "\n",
        "При наличии папки `midas-source` в вашем хранилище, изображения берутся оттуда.\n",
        "\n",
        "В обратном случае изображения берутся из сети. Если вы хотите добавить изображения по URL, заполните массив files словарями следующей структуры, как описано в примере: \n",
        "\n",
        "`{\"url\": *ссылка на изображение*, \"name\": *имя файла с расширением*}`"
      ],
      "metadata": {
        "id": "HhgHE6VUcq6N"
      },
      "id": "HhgHE6VUcq6N"
    },
    {
      "cell_type": "code",
      "source": [
        "supported_formats = ['.png', '.jpg', '.jpeg', '.bmp']\n",
        "\n",
        "if (DRIVE / 'midas-source').is_dir():\n",
        "  files = [f for f in (DRIVE / 'midas-source').iterdir() if f.suffix in supported_formats]\n",
        "  src = [str(f) for f in list(files)]\n",
        "\n",
        "else:\n",
        "  files = [\n",
        "      {\"url\": \"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"name\": \"dog.jpg\"}  # example\n",
        "  ]\n",
        "  src = []\n",
        "  for f in files:\n",
        "    urllib.request.urlretrieve(f[\"url\"], f[\"name\"])\n",
        "    src.append(f[\"name\"])\n",
        "\n",
        "print(f'total images: {len(src)}')"
      ],
      "metadata": {
        "id": "rRq0rLbcPSHs"
      },
      "id": "rRq0rLbcPSHs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "central-spell",
      "metadata": {
        "id": "central-spell"
      },
      "source": [
        "### Выбор модели\n",
        "\n",
        "Вы можете выбрать любую модель из списка:\n",
        "\n",
        "* DPT_Large\n",
        "* DPT_Hybrid\n",
        "* MiDaS_small\n",
        "\n",
        "Для сравнения моделей смотрите [https://github.com/intel-isl/MiDaS/#Accuracy](https://github.com/intel-isl/MiDaS/#Accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "brazilian-reach",
      "metadata": {
        "id": "brazilian-reach"
      },
      "outputs": [],
      "source": [
        "model_type = \"DPT_Large\"     # MiDaS v3 - Large     (highest accuracy, slowest inference speed)\n",
        "#model_type = \"DPT_Hybrid\"   # MiDaS v3 - Hybrid    (medium accuracy, medium inference speed)\n",
        "#model_type = \"MiDaS_small\"  # MiDaS v2.1 - Small   (lowest accuracy, highest inference speed)\n",
        "\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tired-delaware",
      "metadata": {
        "id": "tired-delaware"
      },
      "source": [
        "Используем ГПУ, если такая возможность имеется"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "assisted-count",
      "metadata": {
        "id": "assisted-count"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "midas.to(device)\n",
        "midas.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "extensive-transcript",
      "metadata": {
        "id": "extensive-transcript"
      },
      "source": [
        "Загружаем необходимый для моделей трансформер\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "greenhouse-finder",
      "metadata": {
        "id": "greenhouse-finder"
      },
      "outputs": [],
      "source": [
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "\n",
        "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
        "    transform = midas_transforms.dpt_transform\n",
        "else:\n",
        "    transform = midas_transforms.small_transform"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tested-action",
      "metadata": {
        "id": "tested-action"
      },
      "source": [
        "Функция для записи карты глубины. Преобразуем к .png"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def write_depth(path, depth):\n",
        "\n",
        "    depth_min = depth.min()\n",
        "    depth_max = depth.max()\n",
        "\n",
        "    max_val = 65535 # uint16 max value\n",
        "\n",
        "    if depth_max - depth_min > np.finfo(\"float\").eps:\n",
        "        out = max_val * (depth - depth_min) / (depth_max - depth_min)\n",
        "    else:\n",
        "        out = 0\n",
        "\n",
        "    path = path.replace(Path(path).suffix, '.png')\n",
        "\n",
        "    cv2.imwrite(path, out.astype(\"uint16\"))\n",
        "    \n",
        "    return"
      ],
      "metadata": {
        "id": "2d4k1OR_MYqC"
      },
      "id": "2d4k1OR_MYqC",
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обработка\n",
        "\n",
        "Выполняем преобразование для каждого входного изображения и сохраняем на диск"
      ],
      "metadata": {
        "id": "8XpWM_hxjHaj"
      },
      "id": "8XpWM_hxjHaj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fuzzy-grounds",
      "metadata": {
        "id": "fuzzy-grounds"
      },
      "outputs": [],
      "source": [
        "res_path = (DRIVE / 'midas-result')\n",
        "if not res_path.is_dir():\n",
        "  res_path.mkdir()\n",
        "\n",
        "for filename in src:\n",
        "\n",
        "  try:\n",
        "    img = cv2.imread(filename)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    input_batch = transform(img).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      prediction = midas(input_batch)\n",
        "\n",
        "      prediction = torch.nn.functional.interpolate(\n",
        "          prediction.unsqueeze(1),\n",
        "          size=img.shape[:2],\n",
        "          mode=\"bicubic\",\n",
        "          align_corners=False,\n",
        "      ).squeeze()\n",
        "\n",
        "    output = prediction.cpu().numpy()\n",
        "\n",
        "    out_file = filename.replace('midas-source', 'midas-result')\n",
        "    write_depth(out_file, output)\n",
        "    print(f'{filename} successfully processed.')\n",
        "\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    print(f'{filename} processing failed.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "expanded-verification",
      "metadata": {
        "id": "expanded-verification"
      },
      "source": [
        "### References\n",
        "[Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer](https://arxiv.org/abs/1907.01341)\n",
        "\n",
        "[Vision Transformers for Dense Prediction](https://arxiv.org/abs/2103.13413)\n",
        "\n",
        "Please cite our papers if you use our models."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}